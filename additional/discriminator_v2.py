import torch
import torch.nn as nn

from torchvision import models
from torchvision.models import VGG19_Weights
from torchmetrics.functional import structural_similarity_index_measure

import numpy as np
import random
import kornia
from kornia.geometry.transform import rotate
import torch.nn.functional as F

###
class loss_fusion(nn.Module):
    def __init__(self,coeff_int=1,coeff_grad=1):
        super(loss_fusion, self).__init__()
        self.coeff_int=coeff_int
        self.coeff_grad=coeff_grad

    def forward(self,pre,target):
        loss_int=F.l1_loss(pre,target)
        loss_grad=F.l1_loss(kornia.filters.SpatialGradient()(pre),kornia.filters.SpatialGradient()(target))
        
        loss_total=self.coeff_int*loss_int+self.coeff_grad*loss_grad
        return loss_total

class Transformer():
    def __init__(self, shift_n, rotate_n, flip_n):
        self.shift_n = shift_n
        self.rotate_n = rotate_n
        self.flip_n = flip_n
        self.seed = 1  # 랜덤 시드 저장
        
    def apply(self, x):
        random.seed(self.seed)  # 같은 시드 사용
        
        if self.shift_n>0:
            x_shift=shift_random(x, self.shift_n)
        if self.rotate_n>0:
            x_rotate=rotate_random(x, self.rotate_n)
        if self.flip_n>0:
            x_flip=flip_random(x, self.flip_n)

        if self.shift_n>0:
            x=torch.cat((x,x_shift),0)
        if self.rotate_n>0:
            x=torch.cat((x,x_rotate),0)
        if self.flip_n>0:
            x=torch.cat((x,x_flip),0)
        return x


def shift_random(x, n_trans=5):
    H, W = x.shape[-2], x.shape[-1]
    assert n_trans <= H - 1 and n_trans <= W - 1, f'n_shifts should less than {H-1}'
    shifts_row = random.sample(list(np.concatenate([-1*np.arange(1, H), np.arange(1, H)])), n_trans)
    shifts_col = random.sample(list(np.concatenate([-1*np.arange(1, W), np.arange(1, W)])), n_trans)
    x = torch.cat([torch.roll(x, shifts=[sx, sy], dims=[-2,-1]).type_as(x) for sx, sy in zip(shifts_row, shifts_col)], dim=0)
    return x

def rotate_random(data, n_trans=5, random_rotate=False):
    if random_rotate:
        theta_list = random.sample(list(np.arange(1, 359)), n_trans)
    else:
        theta_list = np.arange(10, 360, int(360 / n_trans))
    data = torch.cat([kornia.geometry.rotate(data, torch.Tensor([theta]).type_as(data)) for theta in theta_list], dim=0)
    return data

def flip_random(data, n_trans=3):
    assert n_trans <= 3, 'n_flip should less than 3'
    
    if n_trans >= 1:
        data1 = kornia.geometry.transform.hflip(data)
    if n_trans >= 2:
        data2 = kornia.geometry.transform.vflip(data)
        data1 = torch.cat((data1, data2), 0)
    if n_trans == 3:
        data1 = torch.cat((data1, kornia.geometry.transform.hflip(data2)), 0)        
    return data1

# Defines the PatchGAN discriminator with the specified arguments.
class NLayerDiscriminator(nn.Module):
    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False, getIntermFeat=False):
        super(NLayerDiscriminator, self).__init__()
        self.getIntermFeat = getIntermFeat
        self.n_layers = n_layers

        kw = 4
        padw = int(np.ceil((kw-1.0)/2))
        sequence = [[nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]]

        nf = ndf
        for n in range(1, n_layers):
            nf_prev = nf
            nf = min(nf * 2, 512)
            sequence += [[
                nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=2, padding=padw),
                norm_layer(nf), nn.LeakyReLU(0.2, True)
            ]]

        nf_prev = nf
        nf = min(nf * 2, 512)
        sequence += [[
            nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=1, padding=padw),
            norm_layer(nf),
            nn.LeakyReLU(0.2, True)
        ]]

        sequence += [[nn.Conv2d(nf, 1, kernel_size=kw, stride=1, padding=padw)]]

        if use_sigmoid:
            sequence += [[nn.Sigmoid()]]

        if getIntermFeat:
            for n in range(len(sequence)):
                setattr(self, 'model'+str(n), nn.Sequential(*sequence[n]))
        else:
            sequence_stream = []
            for n in range(len(sequence)):
                sequence_stream += sequence[n]
            self.model = nn.Sequential(*sequence_stream)

    def forward(self, input):
        if self.getIntermFeat:
            res = [input]
            for n in range(self.n_layers+2):
                model = getattr(self, 'model'+str(n))
                res.append(model(res[-1]))
            return res[1:]
        else:
            return self.model(input)        

class MultiscaleDiscriminator(nn.Module):
    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, 
                 use_sigmoid=False, num_D=3, getIntermFeat=False):
        super(MultiscaleDiscriminator, self).__init__()
        self.num_D = num_D
        self.n_layers = n_layers
        self.getIntermFeat = getIntermFeat
     
        for i in range(num_D):
            netD = NLayerDiscriminator(input_nc, ndf, n_layers, norm_layer, use_sigmoid, getIntermFeat)
            if getIntermFeat:                                
                for j in range(n_layers+2):
                    setattr(self, 'scale'+str(i)+'_layer'+str(j), getattr(netD, 'model'+str(j)))                                   
            else:
                setattr(self, 'layer'+str(i), netD.model)

        self.downsample = nn.AvgPool2d(3, stride=2, padding=[1, 1], count_include_pad=False)

    def singleD_forward(self, model, input):
        if self.getIntermFeat:
            result = [input]
            for i in range(len(model)):
                result.append(model[i](result[-1]))
            return result[1:]
        else:
            return [model(input)]

    def forward(self, input):        
        num_D = self.num_D
        result = []
        input_downsampled = input
        for i in range(num_D):
            if self.getIntermFeat:
                model = [getattr(self, 'scale'+str(num_D-1-i)+'_layer'+str(j)) for j in range(self.n_layers+2)]
            else:
                model = getattr(self, 'layer'+str(num_D-1-i))
            result.append(self.singleD_forward(model, input_downsampled))
            if i != (num_D-1):
                input_downsampled = self.downsample(input_downsampled)
        return result

class GANLoss(nn.Module):
    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0,
                 tensor=torch.FloatTensor):
        super(GANLoss, self).__init__()
        self.real_label = target_real_label
        self.fake_label = target_fake_label
        self.real_label_var = None
        self.fake_label_var = None
        self.Tensor = tensor
        if use_lsgan:
            self.loss = nn.MSELoss()
        else:
            self.loss = nn.BCELoss()

    def get_target_tensor(self, input, target_is_real):
        target_tensor = None
        if target_is_real:
            create_label = ((self.real_label_var is None) or
                            (self.real_label_var.numel() != input.numel()))
            if create_label:
                real_tensor = self.Tensor(input.size()).fill_(self.real_label)
                self.real_label_var = real_tensor.requires_grad_(False)
            target_tensor = self.real_label_var
        else:
            create_label = ((self.fake_label_var is None) or
                            (self.fake_label_var.numel() != input.numel()))
            if create_label:
                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)
                self.fake_label_var = fake_tensor.requires_grad_(False)
            target_tensor = self.fake_label_var
        return target_tensor

    def forward(self, input, target_is_real):
        if isinstance(input[0], list):
            loss = 0
            for input_i in input:
                pred = input_i[-1]
                target_tensor = self.get_target_tensor(pred, target_is_real).to('cuda:0')
                loss += self.loss(pred, target_tensor)
            return loss
        else:            
            target_tensor = self.get_target_tensor(input[-1], target_is_real).to('cuda:0')
            return self.loss(input[-1], target_tensor)

class ImagePool():
    def __init__(self, pool_size):
        self.pool_size = pool_size
        if self.pool_size > 0:
            self.num_imgs = 0
            self.images = []

    def query(self, images):
        if self.pool_size == 0:
            return images
        return_images = []
        for image in images:
            image = torch.unsqueeze(image, 0)
            if self.num_imgs < self.pool_size:
                self.num_imgs += 1
                self.images.append(image)
                return_images.append(image)
            else:
                p = random.uniform(0, 1)
                if p > 0.5:
                    random_id = random.randint(0, self.pool_size - 1)
                    tmp = self.images[random_id].clone()
                    self.images[random_id] = image
                    return_images.append(tmp)
                else:
                    return_images.append(image)
        return_images = torch.cat(return_images, 0)
        return return_images
    
class vgg19(torch.nn.Module):
    def __init__(self, requires_grad=False):
        super(vgg19, self).__init__()
        vgg_pretrained_features = models.vgg19(weights=VGG19_Weights.IMAGENET1K_V1).features
        self.slice1 = torch.nn.Sequential()
        self.slice2 = torch.nn.Sequential()
        self.slice3 = torch.nn.Sequential()
        self.slice4 = torch.nn.Sequential()
        self.slice5 = torch.nn.Sequential()
        for x in range(2):
            self.slice1.add_module(str(x), vgg_pretrained_features[x])
        for x in range(2, 7):
            self.slice2.add_module(str(x), vgg_pretrained_features[x])
        for x in range(7, 12):
            self.slice3.add_module(str(x), vgg_pretrained_features[x])
        for x in range(12, 21):
            self.slice4.add_module(str(x), vgg_pretrained_features[x])
        for x in range(21, 30):
            self.slice5.add_module(str(x), vgg_pretrained_features[x])
        if not requires_grad:
            for param in self.parameters():
                param.requires_grad = False

    def forward(self, X):
        h_relu1 = self.slice1(X)
        h_relu2 = self.slice2(h_relu1)        
        h_relu3 = self.slice3(h_relu2)        
        h_relu4 = self.slice4(h_relu3)        
        h_relu5 = self.slice5(h_relu4)                
        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]
        return out
    
class VGGLoss(nn.Module):
    def __init__(self):
        super(VGGLoss, self).__init__()        
        self.vgg = vgg19().to('cuda:0') # 0?
        self.criterion = nn.L1Loss()
        self.weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]        

    def forward(self, x, y):              
        x_vgg, y_vgg = self.vgg(x), self.vgg(y)
        loss = 0
        for i in range(len(x_vgg)):
            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())        
        return loss

# SSIM Loss 계산 함수
def ssim_loss(img1, img2):
    ssim_value = structural_similarity_index_measure(img1, img2)
    return 1 - ssim_value

## Main Discriminator ##
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.discriminator = MultiscaleDiscriminator(input_nc=3 + 3, getIntermFeat=True)
        self.fake_pool = ImagePool(0)

        self.gan_loss = GANLoss()
        self.criterionFeat = torch.nn.L1Loss()
        self.criterionVGG = VGGLoss()

        self.lambda_feat = 10  # default 10
        self.opt_num = 3

        self.transfor = Transformer(3, 3, 3)
        self.loss_fus = loss_fusion()

    def discriminate(self, input_image, generated_image, use_pool=False):
        input_concat = torch.cat([input_image, generated_image.detach()], dim=1)

        if use_pool:
            fake_query = self.fake_pool.query(input_concat)
            return self.discriminator(fake_query)
        else:
            return self.discriminator(input_concat)

    def forward(self, input_image, real_image, generated_image):
        losses = {}
        # transform loss
        gen_swir_transform = self.transfor.apply(generated_image)
        real_swir_transform = self.transfor.apply(real_image)
        losses['transform_loss'] = self.loss_fus(gen_swir_transform, real_swir_transform)

        # Fake Detection and Loss
        pred_fake_pool = self.discriminate(input_image, generated_image, use_pool=True)
        losses['loss_D_fake'] = self.gan_loss(pred_fake_pool, False)        
        
        # Real Detection and Loss        
        pred_real = self.discriminate(input_image, real_image)
        losses['loss_D_real'] = self.gan_loss(pred_real, True)

        # GAN loss (Fake Passability Loss)        
        pred_fake = self.discriminator(torch.cat([input_image, generated_image], dim=1))        
        losses['loss_G_GAN'] = self.gan_loss(pred_fake, True)     

        # GAN feature matching loss
        loss_G_GAN_Feat = 0
        n_layers_D = 3  # n_layers_D default 3
        feat_weights = 4.0 / (n_layers_D + 1) 
        D_weights = 1.0 / self.opt_num  # default 2 self.opt.num_D
        for i in range(self.opt_num):  # self.opt_num_D
            for j in range(len(pred_fake[i])-1):
                loss_G_GAN_Feat += D_weights * feat_weights * \
                    self.criterionFeat(pred_fake[i][j], pred_real[i][j].detach()) * 5
                
        losses['loss_G_GAN_Feat'] = loss_G_GAN_Feat

        # VGG feature matching loss
        losses['loss_G_VGG'] = self.criterionVGG(input_image, generated_image) * 5

        # SSIM Loss
        losses['loss_G_SSIM'] = ssim_loss(real_image, generated_image) * self.lambda_feat

        return losses

a = Discriminator().to('cuda:0')
b = torch.randn(1, 3, 64, 64).to('cuda:0')
l = a(b, b, b)
print(l)